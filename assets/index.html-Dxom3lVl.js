import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as t,o,f as p}from"./app-NfaswYlV.js";const a={},c=p('<p>Map过程之后、Reduce方程之前，这段数据处理过程被称为 <code>Shuffle</code></p><p>相关博客：</p><ul><li><a href="https://juejin.cn/post/6878277286882181134" target="_blank" rel="noopener noreferrer">https://juejin.cn/post/6878277286882181134</a></li><li><a href="https://juejin.cn/post/7114265145811222558" target="_blank" rel="noopener noreferrer">https://juejin.cn/post/7114265145811222558</a></li></ul><p>要求：将统计结果按照条件输出到不同文件中(分区)。<br> 比如:将统计结果按照手机归属地不同省份输出到不同文件中(分区)</p><p>在Driver类中，通过添加如下配置手动改变一下分区，不改的话，数据少，看不出Shuffle过程</p><div class="language-java line-numbers-mode" data-highlighter="shiki" data-ext="java" data-title="java" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">job</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">setNumReduceTasks</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">);</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>运行一下可以发现，最后的结果出现了两个</p><p>下面是Shuffle的解析</p><p>来看一下之前写过的 <code>Mapper</code> 代码，其他的都是业务代码，所以这里和 <code>Shuffle</code> 有关的代码只有一行代码 <code>context.write(outKey, outValue);</code></p><p>来分析一下这句话。首先从map方法的入参 <code>Mapper&lt;&gt;.Context</code> 中可以看出，context 对象的类是父类 <code>Mapper</code> 中的 <code>Context</code> 内部抽象类</p><p>该抽象类中没有对应的 <code>write</code> 方法，而该抽象类实现了 <code>MapContext</code> 接口，点进去接着看，发现这个接口也没有对应的方法，而且 <code>MapContext</code> 接口实现了 <code>TaskInputOutputContext</code> 接口</p><p>点进去发现，<code>write</code> 方法就在这个接口里，通过debug可以发现接口的实现类是 <code>TaskInputOutputContextImpl</code>。</p><p>在该类中，<code>write</code> 方法对应的实现也只有一行代码，点进方法体中的 <code>write</code> 方法，跳转到了 <code>RecordWriter</code> 抽象类中，通过debug可以发现，这里调用的实现类是 <code>org.apache.hadoop.mapred</code> 包下的 <code>MapTask.NewOutputCollector</code> 内部类，实际调用的 <code>write</code> 方法也是该子类中的方法</p><p>注意，如下是重点！</p><p>点进 <code>write</code> 方法体中的 <code>collect</code> 方法，跳到了 <code>MapOutputCollector</code> 接口中。通过Debug可以发现，该接口的实现类是 <code>MapTask.MapOutputBuffer</code>，也就是 <code>MapTask</code> 类的内部类 <code>MapOutputBuffer</code>，实际调用的 <code>collect</code> 方法，也是这个类中的</p><div class="hint-container tip"><p class="hint-container-title">提示</p><p>之前在工作流程分析中，知道了在环形缓冲区中，内存达到80%就开始 <strong>反向溢写</strong></p><p>具体是怎么做的，可以去看 <code>MapTask.MapOutputBuffer</code> 类中的 <code>init</code> 方法</p></div><p><code>collect</code> 方法的方法体不用多看，直接来看前面给该方法传过来的参数</p><p>前两个参数不用多说了，看一下第三个参数：<code>partitioner.getPartition(key, value, partitions)</code></p><p>这个名为 partitioner 的 <code>Partitioner</code> 接口类型变量的实际对象可以去看 <code>MapTask.NewOutputCollector</code> 类的构造方法</p><p>可以看出，导致接口实现类不同的地方在于 partitions 变量，而这个变量又是 <code>ReduceTask</code> 的个数，这个的个数，我们之前设置过了</p><p>因为 partitions 变量大于1，所以这里他用了一个反射工具类，获取了一个实现类。通过debug可以看出，这里获取的实现类是 <code>org.apache.hadoop.mapreduce.lib.partition</code> 包下的 <code>HashPartitioner</code> 类</p><p>该类中的 <code>getPartition</code> 方法非常简单，key的hashcode 二进制逻辑与 Integer的最大值，再对 ReduceTask 的个数取模</p><p>在这里，用户无法控制哪个key存到哪个分区。</p>',23),i=[c];function d(r,n){return o(),t("div",null,i)}const h=e(a,[["render",d],["__file","index.html.vue"]]),u=JSON.parse('{"path":"/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E6%A1%86%E6%9E%B6/MapReduce%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%90%E7%AE%97%E7%A8%8B%E5%BA%8F/Shuffle%E6%9C%BA%E5%88%B6/","title":"Shuffle机制","lang":"zh-CN","frontmatter":{"title":"Shuffle机制","dir":{"text":"Shuffle机制","order":60,"link":true},"description":"Map过程之后、Reduce方程之前，这段数据处理过程被称为 Shuffle 相关博客： https://juejin.cn/post/6878277286882181134 https://juejin.cn/post/7114265145811222558 要求：将统计结果按照条件输出到不同文件中(分区)。 比如:将统计结果按照手机归属地不同省份输...","head":[["meta",{"property":"og:url","content":"https://mahe666.github.io/doc/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E6%A1%86%E6%9E%B6/MapReduce%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%90%E7%AE%97%E7%A8%8B%E5%BA%8F/Shuffle%E6%9C%BA%E5%88%B6/"}],["meta",{"property":"og:site_name","content":"Mahe666"}],["meta",{"property":"og:title","content":"Shuffle机制"}],["meta",{"property":"og:description","content":"Map过程之后、Reduce方程之前，这段数据处理过程被称为 Shuffle 相关博客： https://juejin.cn/post/6878277286882181134 https://juejin.cn/post/7114265145811222558 要求：将统计结果按照条件输出到不同文件中(分区)。 比如:将统计结果按照手机归属地不同省份输..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-06-16T11:31:59.000Z"}],["meta",{"property":"article:author","content":"Mahe666"}],["meta",{"property":"article:modified_time","content":"2024-06-16T11:31:59.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Shuffle机制\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2024-06-16T11:31:59.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Mahe666\\"}]}"]]},"headers":[],"git":{"createdTime":1718534722000,"updatedTime":1718537519000,"contributors":[{"name":"mahe666","email":"m13234666930@163.com","commits":1}]},"filePathRelative":"大数据/Hadoop分布式存储框架/MapReduce分布式运算程序/Shuffle机制/README.md","localizedDate":"2024年6月16日","autoDesc":true}');export{h as comp,u as data};
