import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{o as a,c as o,f as p}from"./app-DXgo3lxK.js";const r={},s=p('<h2 id="概述" tabindex="-1"><a class="header-anchor" href="#概述"><span>概述</span></a></h2><p>排序是MapReduce框架中最重要的操作之一。</p><p>MapTask和ReduceTask均会对数据<strong>按照key</strong>进行排序。该操作属于Hadoop的默认行为。<strong>任何应用程序中的数据均会被排序，而不管逻辑上是否需要。</strong></p><div class="hint-container caution"><p class="hint-container-title">警告</p><p>Hadoop中所有的数据的Key，都必须能够排序，不能排序的话，就会报错</p></div><p>默认排序是按照<strong>字典顺序排序</strong>，且实现该排序的方法是<strong>快速排序</strong>。</p><p>咱们之前看的Shuffle过程中的几次排序如下：</p><p>在整个的MapTask过程中，进行了两次排序，第一次是在环形缓冲区溢写之前进行了<strong>快速排序</strong>，第二次是在溢写之后进行了<strong>Merge归并排序</strong></p><p>在 Map 阶段结束之后，Reduce阶段主动去拉取对应的数据，拉取过来后在进入到<code>reduce</code>方法之前，它需要对自己拉取过来的数据进行一次<strong>归并排序</strong></p><p>归并排序之后，如果想对Key的内容再进行排序，可以使用<strong>分组排序</strong></p><div class="hint-container tip"><p class="hint-container-title">提示</p><p>思考：为什么需要排序？</p><p>在map方法输出后，相同key的键值对很有可能不挨在一起。而reduce方法的入参是相同key的一组值。</p><p>如果不排序，想要获取相同key的一组值，很有可能需要在reduce方法里面自己去遍历获取</p><p>而如果没有ReduceTask的归并排序，可能需要手动为相同的key获取对应的一组值</p></div><p>这里说的<strong>快速排序</strong>，指的是MapTask过程中的第一次排序</p><p>对于MapTask，它会将处理的结果暂时放到环形缓冲区中，<strong>当环形缓冲区使用率达到一定阈值后，再对缓冲区中的数据进行一次快速排序</strong>，并将这些有序数据溢写到磁盘上，而当数据处理完毕后，它会<strong>对磁盘上所有文件进行归并排序</strong></p><p>对ReduceTask，它从每个MapTask上远程拷贝相应的数据文件，如果文件大小超过一定阈值，则溢写磁盘上，否则存储在内存中。如果磁盘上文件数目达到一定阈值，则进行一次归并排序以生成一个更大文件;如果内存中文件大小或者数目超过一定阈值，则进行一次合并后将数据溢写到磁盘上。当所有数据拷贝完毕后，<strong>ReduceTask统一对内存和磁盘上的所有数据进行一次归并排序</strong>。</p><h2 id="排序分类" tabindex="-1"><a class="header-anchor" href="#排序分类"><span>排序分类</span></a></h2><h3 id="部分排序" tabindex="-1"><a class="header-anchor" href="#部分排序"><span>部分排序</span></a></h3><p>MapReduce根据输入记录的键对数据集排序。保证<strong>输出的每个文件内部有序</strong></p><p>拿之前的 <em>电话流量分区</em> 案例来举例，一个分区形成一个文件，而文件内的数据的排序，就是<strong>部分排序</strong></p><h3 id="全排序" tabindex="-1"><a class="header-anchor" href="#全排序"><span>全排序</span></a></h3><p><strong>最终输出结果只有一个文件，且文件内部有序</strong>。实现方式是只设置一个ReduceTask。但该方法在处理大型文件时效率极低，因为一台机器处理所有文件，完全丧失了MapReduce所提供的并行架构</p><p>在企业中，用到全排序的可能性不太大。因为数据量很有可能达到PB级，一个ReduceTask处理不过来</p><h3 id="辅助排序-groupingcomparator-分组" tabindex="-1"><a class="header-anchor" href="#辅助排序-groupingcomparator-分组"><span>辅助排序（GroupingComparator 分组）</span></a></h3><p>在Reduce端对key进行分组。应用于:在接收的key为bean对象时，想让一个或几个字段相同(全部字段比较不相同)的key进入到同一个reduce方法时，可以采用分组排序。</p><h3 id="二次排序" tabindex="-1"><a class="header-anchor" href="#二次排序"><span>二次排序</span></a></h3><p>在自定义排序过程中，如果 <code>compareTo</code> 方法中的判断条件为两个即为二次排序。</p><h2 id="自定义排序规则" tabindex="-1"><a class="header-anchor" href="#自定义排序规则"><span>自定义排序规则</span></a></h2><p>之前我们自定义的序列化类需要实现 <code>Writable</code> 接口，而我们要实现排序的话，还要实现一个 <code>Comparable</code> 接口</p><p>虽然同时实现两个接口可以做到，但是这样写的话不规范。好在Hadoop官方提供了 <code>WritableComparable</code> 接口，这个接口同时继承了 <code>Writable</code> 和 <code>Comparable</code> 这两个接口</p><p>所以，我们的序列化类，直接去实现 <code>WritableComparable</code> 接口就好</p>',28),n=[s];function t(c,d){return a(),o("div",null,n)}const g=e(r,[["render",t],["__file","index.html.vue"]]);export{g as default};
