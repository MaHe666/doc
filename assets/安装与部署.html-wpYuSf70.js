import{_ as o}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as c,o as i,c as l,d as e,e as a,a as n,f as d}from"./app-CRxPAwu9.js";const t={},p=d('<div class="hint-container tip"><p class="hint-container-title">提示</p><ul><li>这里使用的Linux版本是 <code>CentOS7</code></li><li>这里使用的Hadoop版本是 <code>Hadoop-3.3.6</code></li><li>这里使用的JDK版本是 <code>8</code></li></ul></div><h2 id="hadoop源码编译部署" tabindex="-1"><a class="header-anchor" href="#hadoop源码编译部署"><span>Hadoop源码编译部署</span></a></h2><p>匹配不同操作系统本地库环境，Hadoop某些操作比如压缩、I0需要调用系统本地库(<code>*.so</code>|<code>*.dl1</code>)</p><p>带有 <code>src</code> 字样的 <code>.tar.gz</code> 文件就是源码包，查看源码包根路径下的 <code>BUILDING.txt</code>，查看都需要什么环境，然后编译即可</p><p>相关博客：</p>',5),r={href:"https://zhuanlan.zhihu.com/p/447274945",target:"_blank",rel:"noopener noreferrer"},h={href:"https://blog.csdn.net/weixin_45835339/article/details/123974591",target:"_blank",rel:"noopener noreferrer"},u=d(`<p>某些公司会优化源代码，编译后使Hadoop更契合自己的业务</p><h2 id="hadoop集群角色规划" tabindex="-1"><a class="header-anchor" href="#hadoop集群角色规划"><span>Hadoop集群角色规划</span></a></h2><p>例如，公司给你1000台服务器，让你去搭建Hadoop集群和其他软件，怎样做一个合理规划？</p><p>例如某个软件的运行依赖于大内存，那就尽量去给它分配到大内存的服务器上</p><p>如果某两个软件的运行互相冲突，那就尽量给他们避开一点</p><div class="hint-container tip"><p class="hint-container-title">提示</p><p>资源上有抢夺冲突的，尽量不要部署在一起</p><p>工作上需要相互配合的，尽量部署在一起</p></div><h2 id="处理虚拟机" tabindex="-1"><a class="header-anchor" href="#处理虚拟机"><span>处理虚拟机</span></a></h2><p>为了更happy的学习Hadoop，建议内存为 4G，硬盘为 50G</p><p>首先配置三台 <code>Linux</code>虚拟机，分别为 <code>testHadoop1</code>、<code>testHadoop2</code>、<code>testHadoop3</code></p><h3 id="下载通用软件" tabindex="-1"><a class="header-anchor" href="#下载通用软件"><span>下载通用软件</span></a></h3><p>安装一些Linux用的软件</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token comment"># 额外软件包</span>
yum <span class="token function">install</span> <span class="token parameter variable">-y</span> epel-release

<span class="token comment"># 最小安装的Linux系统需要安装如下软件</span>
yum <span class="token function">install</span> <span class="token parameter variable">-y</span> net-tools

yum <span class="token function">install</span> <span class="token parameter variable">-y</span> <span class="token function">vim</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="关闭防火墙" tabindex="-1"><a class="header-anchor" href="#关闭防火墙"><span>关闭防火墙</span></a></h3><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token comment"># 关闭防火墙</span>
systemctl stop firewalld

<span class="token comment"># 禁用防火墙开机自启动</span>
systemctl disable firewalld.service
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>企业开发时，通常情况下，服务器之间的防火墙是关闭的。公司会将整个服务器机组对外设置防火墙</p><h3 id="修改虚拟机ip和hostname" tabindex="-1"><a class="header-anchor" href="#修改虚拟机ip和hostname"><span>修改虚拟机IP和Hostname</span></a></h3><p>修改IP的话需要配置 <code>/etc/sysconfig/network-scripts/ifcfg-ens33</code>、<code>/etc/hostname</code> 和 <code>/etc/hosts</code> 文件</p><ul><li><code>/etc/sysconfig/network-scripts/ifcfg-ens33</code>：配置静态ip</li><li><code>/etc/hostname</code>：配置当前主机名称</li><li><code>/etc/hosts</code>：配置ip别名，将包括本机在内的所有Hadoop集群中服务器，都配置一下别名</li></ul><h2 id="安装及配置环境变量" tabindex="-1"><a class="header-anchor" href="#安装及配置环境变量"><span>安装及配置环境变量</span></a></h2><blockquote><p>在开始之前，选中其中一台机器，根据如下内容安装JDK和Hadoop。然后将内容分发到其他机器上</p><p>需要使用 <code>tar.gz安装包</code> 在 <code>/opt/module</code> 目录下 安装JDK，并且配置好环境变量</p><p>注意查看是否有系统自带的JDK</p><p>成功安装后再进行如下操作</p><p>注：明确解压缩路径是为了分发安装软件后的内容</p></blockquote><p>解压Hadoop压缩包至 <code>/opt/module</code> 下，解压后的文件会自动组成一个文件夹</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token function">tar</span> <span class="token parameter variable">-zxvf</span> hadoop安装包 <span class="token parameter variable">-C</span> /opt/module
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h3 id="配置环境变量" tabindex="-1"><a class="header-anchor" href="#配置环境变量"><span>配置环境变量</span></a></h3><p>在 <code>/etc/profile.d</code> 中创建文件 <code>hadoop_env.sh</code> 文件</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token function">touch</span> hadoop_env.sh
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>将如下内容放进去</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token comment">#HADOOP_HOME</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_HOME</span><span class="token operator">=</span>/opt/module/hadoop-3.3.6
<span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token environment constant">$PATH</span><span class="token builtin class-name">:</span><span class="token variable">$HADOOP_HOME</span>/bin:<span class="token variable">$HADOOP_HOME</span>/sbin
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>使配置文件生效</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token builtin class-name">source</span> /etc/profile
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>查看Hadoop版本</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code>hadoop version
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>查看Hadoop安装路径</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token function">which</span> hadoop
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h3 id="hadoop目录结构及介绍" tabindex="-1"><a class="header-anchor" href="#hadoop目录结构及介绍"><span>Hadoop目录结构及介绍</span></a></h3><ul><li><p><code>bin</code>:Hadoop相关服务（<code>hdfs</code>、<code>yarn</code>、<code>mapred</code>）的操作脚本存放在此目录下，但是通常使用的脚本在sbin目录下。</p></li><li><p><code>etc</code>:Hadoop配置文件存放在此目录下，主要包含<code>core-site.xml</code>、<code>hdfs-site.xml</code>、<code>mapred-site.xml</code> 等从 Hadoop1.0 继承而来的配置文件和 <code>yarn-site.xml</code> 等 Hadoop2.0 新增的配置文件。</p></li><li><p><code>lib</code>:Hadoop对外提供的编程动态库和静态库存放在此目录下。</p></li><li><p><code>sbin</code>:Hadoop管理脚本存放在此目录下，主要包含hadoop单机运行、HDFS和YARN中各类服务的启动/关闭脚本。</p></li><li><p><code>src</code>:Hadoop的源码包存放在此目录下。</p></li><li><p><code>share</code>:存放Hadoop的依赖 jar 包、文档、和官方案例</p></li></ul><h3 id="hadoop配置文件及介绍" tabindex="-1"><a class="header-anchor" href="#hadoop配置文件及介绍"><span>Hadoop配置文件及介绍</span></a></h3><ul><li><p><code>hadoop-env.sh</code>:配置Hadoop运行所需的环境变量</p></li><li><p><code>yarn-env.sh</code>:配置Yarn运行所需的环境变量</p></li><li><p><code>core-site.xml</code>:Hadoop核心全局配置文件，可在其他配置文件中引用该文件</p></li><li><p><code>hdfs-site.xml</code>:HDFS配置文件，继承<code>core-site.xml</code>配置文件</p></li><li><p><code>mapred-site.xml</code>:MapReduce配置文件，继承<code>core-site.xml</code>配置文件</p></li><li><p><code>yarn-site.xml</code>:Yarn配置文件，继承<code>core-site.xml</code>配置文件</p></li></ul><h2 id="运行模式" tabindex="-1"><a class="header-anchor" href="#运行模式"><span>运行模式</span></a></h2><p>Hadoop运行模式包括：<code>本地模式</code>、<code>伪分布式模式</code> 和 <code>完全分布式模式</code></p><ul><li><p><code>本地模式</code>：单机运行，只是用来演示一下官方案例。生产环境不用。</p></li><li><p><code>伪分布式模式</code>：也是单机运行，但是具备Hadoop集群的所有功能，一台服务器模拟一个分布式的环境，生产环境不用。（个别缺钱的公司用来测试）</p></li><li><p><code>完全分布式模式</code>：多台服务器组成分布式环境，<strong>生产环境使用</strong></p></li></ul><h3 id="本地模式" tabindex="-1"><a class="header-anchor" href="#本地模式"><span>本地模式</span></a></h3><p>使用官方的 <code>WordCount</code> 案例</p><p>进入到hadoop根目录下，在当前目录下创建文件夹 <code>wcinput</code></p><p>在 <code>./wcinput</code> 路径下，创建文件 <code>word.txt</code>，写上如下内容</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token function">vim</span> ./wcinput/word.txt
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><div class="language-txt line-numbers-mode" data-ext="txt" data-title="txt"><pre class="language-txt"><code>hadoop hadoop hadoop
java java java java
mahe666 mahe666
mahe233
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>然后输入命令</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code>hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar wordcount wcinput/ wcoutput/
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><div class="hint-container tip"><p class="hint-container-title">提示</p><p>解析如下</p><ul><li><code>hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar wordcount</code>：运行官方示例中的jar包里的wordcount</li><li><code>wcinput/</code>：输入路径（word.txt 文件所在路径）</li><li><code>wcoutput/</code>：输出结果的地方，如果输出时存在该文件夹，则会报错</li></ul></div><p>查看结果</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token function">cat</span> ./wcoutput/part-r-00000
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>输出结果如下</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>hadoop  3
java    4
mahe233 1
mahe666 2
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="集群分发脚本" tabindex="-1"><a class="header-anchor" href="#集群分发脚本"><span>集群分发脚本</span></a></h2><p>上面的做完，我们准备开始搭建完全分布式模式了</p><p>先不急着去给其他两个服务器安装软件</p><p>因为这里要用 <code>分发脚本</code> 来拷贝过去</p><h3 id="scp-secure-copy-安全拷贝" tabindex="-1"><a class="header-anchor" href="#scp-secure-copy-安全拷贝"><span>scp(secure copy) 安全拷贝</span></a></h3><p><strong>定义</strong>：scp可以实现服务器与服务器之间的数据拷贝</p><p><strong>基本语法</strong>：<code>scp -r 本机文件夹路径 远程机用户@远程机IP:远程机文件夹路径</code></p><ul><li><code>scp</code>：命令</li><li><code>-r</code>：递归</li><li><code>本机文件夹路径</code>：需要拷贝本地哪个路径下的哪个文件夹，写绝对路径指定</li><li><code>远程机用户@远程机IP:远程机文件夹路径</code>：这里面的 <code>@</code> 和 <code>:</code> 符号不能省略。如果我需要将本机上的 <code>/opt/module</code> 文件夹下的所有内容拷贝过去，那么远程文件夹路径就需要写 <code>/opt</code>（注意确保远程机有 <code>/opt</code> 地址）</li></ul><p>操作如下</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token comment"># 可以这样写</span>
<span class="token function">scp</span> <span class="token parameter variable">-r</span> /opt/module root@192.168.100.102:/opt

<span class="token comment"># 也可以这样写</span>
<span class="token function">scp</span> <span class="token parameter variable">-r</span> /opt/module/* root@192.168.100.103:/opt/module
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="rsync-远程同步工具" tabindex="-1"><a class="header-anchor" href="#rsync-远程同步工具"><span>rsync 远程同步工具</span></a></h3><p>相关博客：</p>`,65),v={href:"https://blog.csdn.net/zhangxueleishamo/article/details/80094875",target:"_blank",rel:"noopener noreferrer"},m={href:"https://blog.csdn.net/Luckyyhr/article/details/116446239",target:"_blank",rel:"noopener noreferrer"},b=d('<p><strong>定义</strong>：<code>rsync</code> 主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。</p><p><strong>rsync 和 scp 区别</strong>：用 <code>rsync</code> 做文件的复制要比 <code>scp</code> 的速度快，<code>rsync</code> 只对差异文件做更新。<code>scp</code> 是把所有文件都复制过去</p><p><strong>基本语法</strong>：<code>rsync -av 本机文件夹路径 远程机用户@远程机IP:远程机文件夹路径</code></p><ul><li><code>rsync</code>：命令</li><li><code>-av</code>：选项参数。<code>-a</code>代表归档拷贝，<code>-v</code>代表显示复制过程</li></ul><h3 id="xsync-集群分发脚本" tabindex="-1"><a class="header-anchor" href="#xsync-集群分发脚本"><span>xsync 集群分发脚本</span></a></h3>',5),g={href:"https://blog.csdn.net/qq_43066945/article/details/119458718",target:"_blank",rel:"noopener noreferrer"},x=e("h3",{id:"配置环境变量-1",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#配置环境变量-1"},[e("span",null,"配置环境变量")])],-1),f=e("div",{class:"hint-container warning"},[e("p",{class:"hint-container-title"},"注意"),e("p",null,"同步之后不要忘记配置环境变量")],-1);function _(k,H){const s=c("ExternalLinkIcon");return i(),l("div",null,[p,e("ul",null,[e("li",null,[e("a",r,[a("https://zhuanlan.zhihu.com/p/447274945"),n(s)])]),e("li",null,[e("a",h,[a("https://blog.csdn.net/weixin_45835339/article/details/123974591"),n(s)])])]),u,e("ul",null,[e("li",null,[e("a",v,[a("https://blog.csdn.net/zhangxueleishamo/article/details/80094875"),n(s)])]),e("li",null,[e("a",m,[a("https://blog.csdn.net/Luckyyhr/article/details/116446239"),n(s)])])]),b,e("p",null,[a("相关博客："),e("a",g,[a("https://blog.csdn.net/qq_43066945/article/details/119458718"),n(s)])]),x,f])}const O=o(t,[["render",_],["__file","安装与部署.html.vue"]]);export{O as default};
