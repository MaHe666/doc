import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as o,o as c,f as d}from"./app-_JAIXX3j.js";const t={},p=d('<h2 id="相关视频" tabindex="-1"><a class="header-anchor" href="#相关视频"><span>相关视频</span></a></h2><p><a href="https://www.bilibili.com/video/BV1Qp4y1n7EN?p=88&amp;vd_source=de9cfd633cf5a71794dc91a35f34cd48" target="_blank" rel="noopener noreferrer">https://www.bilibili.com/video/BV1Qp4y1n7EN?p=88&amp;vd_source=de9cfd633cf5a71794dc91a35f34cd48</a></p><h2 id="job提交流程" tabindex="-1"><a class="header-anchor" href="#job提交流程"><span>Job提交流程</span></a></h2><p>之前的Driver类中，主要写就是 <code>org.apache.hadoop.mapreduce</code> 包下的 <code>Job类</code> 相关的代码</p><p>而写出来的这些代码中，前面的代码都是在设置Job的相关内容，例如Mapper的类、Reduce的类、设置输出类型和文件读写路径等。</p><p>前面的代码没什么值得详细说的，最后这个Job对象被 <strong>提交</strong>，并且返回了一个运行结果，这里才是重点。</p><p>点进 <code>waitForCompletion</code> 方法，在该方法的方法体的最上面，有一个if判断，查看源代码可得知，该类的实例的 <code>state</code> 属性的默认值就是 <code>JobState.DEFINE</code>，所以这里为true，<code>submit</code> 方法被调用</p><p>点进 <code>submit</code> 方法，发现一上来就调用了三个方法</p><p>第一个方法 <code>ensureState</code> 没啥说的，看名字并联系上下文就知道该方法是用来确保state属性是正确的。点进去看方法体，代码的意思很简单：如果检测到 <code>state</code> 不对就抛异常</p><p>第二个方法 <code>setUseNewAPI</code> 比较特别，简单概括一下，<strong>该方法解决了新旧两套API的兼容问题</strong></p><p>第三个方法 <code>connect</code> 处理的是客户端与服务器集群的连接。可以思考一下，正常情况来说，客户端连接服务器集群需要YARN。但是目前没有启动服务器集群的话，或者说我现在在代码里面根本没有配置服务器集群的地址，它连接的是谁？之前咱们给出过答案，它连接的是本地环境。那这个Job提交的流程是什么样的？</p><p>来看一下 <code>connect</code> 方法的代码，上来就校验 <strong>cluster</strong> 对象是否为空，这个单词的翻译是 <strong>簇</strong>，这里可以理解为是集群。如果该对象是空，则给该对象赋值</p><p>赋值操作调用了 <code>ugi</code> 对象的 <code>doAs</code> 方法，该方法的参数是一个 <code>PrivilegedExceptionAction</code> 接口的实例对象。因为是接口，所以必须要实现其中的抽象方法，咱们需要的是 <code>Cluster</code> 对象，所以通过泛型等操作，该方法创建了一个<code>Cluster</code> 类实例，并传入了 <code>getConfiguration</code> 方法的返回值作为参数。</p><p><code>PrivilegedExceptionAction</code> 这个接口先不管，直接来看 <code>Cluster</code> 类的构造方法，可以发现该构造方法调用了另一个构造方法，找到根源，也就是那个需要两个参数的构造方法</p><p>该构造方法中，前两个是对象属性的赋值，没啥好说的，接着来看 <code>initialize</code> 方法</p><p><code>initialize</code> 方法的第一行代码，调用了 <code>initProviderList</code> 方法，这个方法点进去简单看一下，该方法的作用是初始化了一个名为 <code>providerList</code> 的对象。点一下 <code>providerList</code> 集合，可以发现它是一个泛型为 <code>ClientProtocolProvider</code> 类的List集合</p><p>接着往下看 <code>initialize</code> 方法，可以看到有一个增强for循环，被循环的对象就是刚才提到的 <code>providerList</code> 集合。</p><p>学员可以通过debug查看 <code>providerList</code> 集合中都有什么类的对象。这里直接说，点进刚才提到的 <code>ClientProtocolProvider</code> 抽象类，可以通过IDE，查看到它有两个实现类：<code>YarnClientProtocolProvider</code> 和 <code>LocalClientProtocolProvider</code>。在 <code>providerList</code> 集合中，这两个对象是都存在的</p><p>只不过在这里，经过 <code>initialize</code> 方法中for循环里的一堆if，保留下来了 <code>LocalClientProtocolProvider</code> 对象</p><p>所以，这里连接的是本地环境。（具体的判定逻辑不用管）</p><p>然后往下走，一层一层的就又退出到 <code>submit</code> 方法中。至此，<code>connect</code> 方法执行完毕</p><p><code>connect</code> 方法执行完毕之后，往下看，创建了一个 <code>JobSubmitter</code> 类的实例对象。通过该对象的 <code>submitJobInternal</code> 方法，向集群提交了相关的Job信息。这里也是个核心代码</p><p>点进该方法，进来之后，第一个方法就是 <code>checkSpecs</code>，该方法实际校验的就是输出的相关信息。</p><p>点进 <code>checkSpecs</code> 方法，该方法中的if判断有点繁琐，实际判断的是三元运算符中返回的两个值。</p><p>查看接下来 <code>org.apache.hadoop.mapreduce</code> 包下的 <code>OutputFormat</code> 类的实际对象所调用的 <code>checkOutputSpecs</code> 方法</p><p>默认调用的是 <code>OutputFormat</code> 抽象类的 <code>FileOutputFormat</code> 实现类。查看实现类中的 <code>checkOutputSpecs</code> 方法</p><p>往下翻，可以看见校验了路径，按照对应的校验方式，如果路径有问题，就会弹出相应的报错。</p><p><code>checkOutputSpecs</code> 方法执行完后，外层的 <code>checkSpecs</code> 方法也就执行完了</p><p>往下看，<code>addMRFrameworkToDistributedCache</code> 方法不用多说，看名字就知道作用是将 <code>MapReduce框架添加到已经分发的缓存</code> 中</p><p>再往下，就获取了一个名为 <code>jobStagingArea</code> 的 <code>Path</code> 对象。注意，这个类是 <code>org.apache.hadoop.fs</code> 包下的</p><p>可以通过Debug查看该路径的具体值是什么，抽象来说是 <code>/tmp/hadoop.mapred/staging/文件夹/.staging</code>（Windows系统的根路径要看代码在哪个盘下，然后去对应的盘下的根路径去找就可以）。每一次执行，他这个文件夹都不一样，建议使用Debug一点一点执行，也方便观察最后的 <code>.staging</code> 文件夹里有什么变化</p><p>往下看代码，一直到if语句执行完，获取了本地的一些信息，然后拿着这些信息进行了一些配置</p><p>再往下看，可以看到一个对象调用了 <code>getNewJobID</code> 方法，并返回了一个 <code>JobID</code> 对象</p><p>然后往下看，创建了一个提交Job的 <code>Path</code> 路径对象。这个路径就是在上面的 <code>.staging</code> 文件夹下的（注意，这里还没创建文件夹呢）</p><p>然后一直往下翻，中间的代码全都是处理缓存，不用管，一直翻到 <code>copyAndConfigureFiles</code> 方法，点击进去看一下里面长什么样子</p><p>直接来看方法的核心部分，通过构造方法创建的 <code>JobResourceUploader</code> 类对象，调用了名为 <code>uploadResources</code> 方法</p><p>点进该方法，可以看到一共调用了三个方法，第一个是初始化了共享的缓存，最后一个是结束了共享的缓存。来看一下中间的 <code>uploadResourcesInternal</code> 方法</p><p>这个方法前面还是处理配置、打印日志、抛出异常什么的，然后可以看见下面又创建了一个 <code>Path</code> 对象，可以发现和上面用来提交Job的 <code>Path</code> 对象的<strong>值</strong>是一样的</p><p>再往下看可以发现有一个 <code>mkdir</code> 方法。这个方法执行完之后，用来提交Job的路径才被创建完成。</p><p>再往下看，中间的代码不用管，直接找到 <code>uploadFiles</code>、<code>uploadLibJars</code>、<code>uploadArchives</code>、<code>uploadJobJar</code>，这四个方法是向集群提交一些文件</p><p>重点来说一下最后一个 <code>uploadJobJar</code>，如果我们当前是在集群模式下，自己编写的代码的Jar包，就可以通过客户端的方式，上传到集群</p><p>所以，整个 <code>copyAndConfigureFiles</code> 方法，如果是本地模式下，就不用提交文件；如果是集群模式下，就需要提交文件。</p><p>代码读到这里，看一下刚才说的job文件夹，里面就有了对应的<strong>4个</strong>文件，可以看一下 <code>job.split</code> 文件，内容有乱码，但是大致是可以看出来都有什么内容的</p><p>退出了 <code>copyAndConfigureFiles</code> 方法后，接着往下看。下面调用了一个重要的方法，名叫 <code>writeSplits</code>，并把切片的返回值，也就是切片数量赋值给了 <code>maps</code> 变量</p><div class="hint-container tip"><p class="hint-container-title">提示</p><p><code>writeSplits</code> 方法中涉及的东西较多，之后单开一部分详细说</p></div><p>紧贴着这行代码的下一行代码的作用是，设置 <code>MapTask</code> 的数量，具体是通过什么设置的，可以点进 <code>MRJobConfig.NUM_MAPS</code> 看一下</p><p>代码接着往下走，一直到 <code>writeConf</code> 方法。Debug可以看出来，在执行完该方法后，job文件夹内又多出两个文件。</p><p>点开这两个里面的 xml文件，可以看见，里面存放的全是运行这个job的参数，也就是说这个job是通过这个参数执行任务</p><p>代码接着往下走，可以看到有个 <code>status</code> 对象，简单提一下，这个对象里保存的是客户端提交的job信息</p><p>再接着往下一直走，代码就开始不断地返回到上层了。一直到<code>Job</code> 类的 <code>submitJobInternal</code> 方法执行完毕，也就是回到了一开始提到的 <code>submit</code> 方法里</p><p>下一行代码很简单，将job状态置为RUNNING。这个Job就开始运行了。</p><p>再往下执行，再跳出，然后就回到了一开始提到的 <code>waitForCompletion</code> 方法中，再往下就是监控程序的代码了</p><p>但是到这里，一直都没有看到什么时候删除的 job文件夹下的6个文件，只需要让他将监控程序的代码执行完毕，他自己就删掉了</p><p>可以通过Debug查看 <code>monitorAndPrintJob</code> 方法执行完毕后，6个文件是否还存在</p><p>以上就是所有的Job提交流程了</p>',55),i=[p];function r(a,n){return c(),o("div",null,i)}const b=e(t,[["render",r],["__file","Job提交流程源码.html.vue"]]),u=JSON.parse('{"path":"/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E6%A1%86%E6%9E%B6/MapReduce%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%90%E7%AE%97%E7%A8%8B%E5%BA%8F/Job%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B%E6%BA%90%E7%A0%81.html","title":"Job提交流程源码","lang":"zh-CN","frontmatter":{"title":"Job提交流程源码","order":40,"description":"相关视频 https://www.bilibili.com/video/BV1Qp4y1n7EN?p=88&vd_source=de9cfd633cf5a71794dc91a35f34cd48 Job提交流程 之前的Driver类中，主要写就是 org.apache.hadoop.mapreduce 包下的 Job类 相关的代码 而写出来的这些代码中，...","head":[["meta",{"property":"og:url","content":"https://mahe666.github.io/doc/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E6%A1%86%E6%9E%B6/MapReduce%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%90%E7%AE%97%E7%A8%8B%E5%BA%8F/Job%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B%E6%BA%90%E7%A0%81.html"}],["meta",{"property":"og:site_name","content":"Mahe666"}],["meta",{"property":"og:title","content":"Job提交流程源码"}],["meta",{"property":"og:description","content":"相关视频 https://www.bilibili.com/video/BV1Qp4y1n7EN?p=88&vd_source=de9cfd633cf5a71794dc91a35f34cd48 Job提交流程 之前的Driver类中，主要写就是 org.apache.hadoop.mapreduce 包下的 Job类 相关的代码 而写出来的这些代码中，..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-06-16T11:31:59.000Z"}],["meta",{"property":"article:author","content":"Mahe666"}],["meta",{"property":"article:modified_time","content":"2024-06-16T11:31:59.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Job提交流程源码\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2024-06-16T11:31:59.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Mahe666\\"}]}"]]},"headers":[{"level":2,"title":"相关视频","slug":"相关视频","link":"#相关视频","children":[]},{"level":2,"title":"Job提交流程","slug":"job提交流程","link":"#job提交流程","children":[]}],"git":{"createdTime":1716212970000,"updatedTime":1718537519000,"contributors":[{"name":"mahe666","email":"m13234666930@163.com","commits":1}]},"filePathRelative":"大数据/Hadoop分布式存储框架/MapReduce分布式运算程序/Job提交流程源码.md","localizedDate":"2024年5月20日","autoDesc":true}');export{b as comp,u as data};
